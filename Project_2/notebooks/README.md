# Step 4: Case Study - Data Analysis

## üìã Vue d'Ensemble

Ce dossier contient le **Jupyter Notebook principal** pour l'analyse et la cat√©gorisation des avis utilisateurs Amazon via des algorithmes NLP (Natural Language Processing).

**Objectif** : D√©velopper un syst√®me automatis√© de classification th√©matique et de scoring de pertinence des reviews.

---

## üìÅ Structure du Projet

```
project_2/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ step_4_case_study/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Step_4_Case_Study_Analysis.ipynb    ‚≠ê Notebook principal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ README.md                           üìÑ Ce fichier
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ sql_queries/                            üìÇ Requ√™tes SQL Snowflake
‚îÇ       ‚îú‚îÄ‚îÄ 01_data_extraction.sql              ‚Üí Extraction des donn√©es
‚îÇ       ‚îú‚îÄ‚îÄ 02_data_aggregation.sql             ‚Üí Agr√©gations pour dashboard
‚îÇ       ‚îî‚îÄ‚îÄ 03_advanced_analysis.sql            ‚Üí Analyses avanc√©es
‚îÇ
‚îú‚îÄ‚îÄ data/outputs/
‚îÇ   ‚îú‚îÄ‚îÄ visualizations/                         üìä Graphiques g√©n√©r√©s
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_eda_stats_generales.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_eda_stats_par_rating.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 07_confidence_distribution.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 09_relevance_distribution.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 10_category_rating_heatmap.html
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 10_wordclouds_by_category.png
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                                 ü§ñ Mod√®les entra√Æn√©s (futurs)
‚îÇ   ‚îî‚îÄ‚îÄ processed/                              üíæ Donn√©es pr√©par√©es
‚îÇ       ‚îú‚îÄ‚îÄ reviews_analyzed.parquet
‚îÇ       ‚îú‚îÄ‚îÄ category_stats.csv
‚îÇ       ‚îî‚îÄ‚îÄ top_reviews.csv
‚îÇ
‚îú‚îÄ‚îÄ dashboards/                                 üé® Application Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ streamlit_app.py                        ‚Üí App principale
‚îÇ   ‚îú‚îÄ‚îÄ pages/                                  ‚Üí Pages multi-pages
‚îÇ   ‚îú‚îÄ‚îÄ components/                             ‚Üí Composants r√©utilisables
‚îÇ   ‚îî‚îÄ‚îÄ utils/                                  ‚Üí Utilitaires (DB, processing)
‚îÇ
‚îî‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ step_4_analysis_report.md               üìÑ Rapport final (5-10 pages)
    ‚îî‚îÄ‚îÄ figures/                                ‚Üí Figures pour le rapport
```

---

## üöÄ D√©marrage Rapide

### 1. Pr√©requis

```bash
# Installer les d√©pendances Python
pip install snowflake-connector-python
pip install transformers torch
pip install nltk pandas numpy matplotlib seaborn plotly
```

### 2. Configuration Snowflake

Mettre √† jour les credentials dans le notebook (Section 2.3) :

```python
conn_params = {
    'account': 'YOUR_ACCOUNT',
    'user': 'YOUR_USER',
    'password': 'YOUR_PASSWORD',
    'warehouse': 'YOUR_WAREHOUSE',
    'database': 'YOUR_DATABASE',
    'schema': 'YOUR_SCHEMA'
}
```

### 3. Ex√©cution

1. Ouvrir `Step_4_Case_Study_Analysis.ipynb` dans Jupyter/VS Code
2. Ex√©cuter les cellules s√©quentiellement (Shift+Enter)
3. Suivre les instructions dans chaque section

---

## üìä Contenu du Notebook

### Section 1 : Introduction & Contexte
- Probl√©matique business
- Objectifs de l'analyse
- Questions de recherche

### Section 2 : Configuration & Connexion
- Installation des d√©pendances
- Import des biblioth√®ques
- Connexion √† Snowflake

### Section 3 : Extraction des Donn√©es
- S√©lection du produit √©chantillon
- Extraction des reviews depuis Snowflake
- Nettoyage des donn√©es

### Section 4 : Analyse Exploratoire (EDA)
- Statistiques descriptives
- Visualisations (ratings, longueur, images)
- Insights cl√©s

### Section 5 : Choix de l'Algorithme
- Comparaison des approches NLP
- Justification du choix (Zero-Shot Classification)
- D√©finition des cat√©gories m√©tier

### Section 6 : Impl√©mentation NLP
- Initialisation du mod√®le (BART/mDeBERTa)
- Fonction de classification
- Application sur l'√©chantillon

### Section 7 : V√©rification & Performance
- M√©triques de convergence
- Confidence score distribution
- Validation manuelle

### Section 8 : Tests It√©ratifs
- Exp√©rimentation 1 : Regroupement de cat√©gories
- Exp√©rimentation 2 : Filtrage des reviews courtes
- Exp√©rimentation 3 : Comparaison de mod√®les

### Section 9 : Relevance Score
- Formule multi-crit√®res (5 composantes)
- Calcul des sous-scores
- Distribution et classification

### Section 10 : Visualisations & Insights
- Heatmap cat√©gories vs ratings
- Top reviews pertinentes
- Word clouds par cat√©gorie
- Insights m√©tier

### Section 11 : Pr√©paration Dashboard
- Agr√©gations pour Streamlit
- Export vers Snowflake/fichiers locaux
- Structure du dashboard

### Section 12 : Limitations & Recommandations
- Limitations identifi√©es
- Roadmap d'am√©lioration (court/moyen/long terme)
- M√©triques de succ√®s

### Section 13 : Livrables & Export
- Checklist de compl√©tion
- Export du rapport final
- Documentation

---

## üéØ Algorithme de Classification

### Zero-Shot Classification

**Mod√®le** : `facebook/bart-large-mnli` (ou `mDeBERTa-v3` pour multilingue)

**Cat√©gories m√©tier** :
1. **Product Quality or Satisfaction** : Qualit√©, performance, satisfaction
2. **Product Defect or Damaged Item** : D√©fauts, probl√®mes, dommages
3. **Delivery Issue or Shipping Delay** : Livraison, d√©lais, packaging
4. **Customer Service or Support** : SAV, remboursement, support

**Avantages** :
- Pas de labeling manuel requis
- Flexibilit√© (ajustement des cat√©gories sans r√©-entra√Ænement)
- Performance acceptable (70-85%)

---

## üìà Relevance Score

### Formule

```python
relevance_score = (
    0.25 √ó text_length_score      # Gaussienne centr√©e sur 300 caract√®res
  + 0.20 √ó has_image              # Pr√©sence d'image (0 ou 1)
  + 0.15 √ó has_orders             # Achat v√©rifi√© (0 ou 1)
  + 0.15 √ó is_extreme_rating      # Rating 1‚òÖ ou 5‚òÖ (0 ou 1)
  + 0.25 √ó sentiment_score        # VADER sentiment (0-1)
) √ó 100
```

**√âchelle** : 0-100 (plus √©lev√© = plus pertinent)

**Seuil de pertinence** : 80/100 (identifie le top 15-20% des reviews)

---

## üì¶ Livrables

### ‚úÖ Fichiers g√©n√©r√©s par le notebook

1. **Visualisations** (8 graphiques) :
   - `data/outputs/visualizations/*.png|html`

2. **Donn√©es pr√©par√©es** :
   - `data/outputs/processed/reviews_analyzed.parquet` (dataset complet)
   - `data/outputs/processed/category_stats.csv` (statistiques par cat√©gorie)
   - `data/outputs/processed/top_reviews.csv` (reviews pertinentes)

3. **SQL Queries** (3 fichiers) :
   - `notebooks/sql_queries/01_data_extraction.sql`
   - `notebooks/sql_queries/02_data_aggregation.sql`
   - `notebooks/sql_queries/03_advanced_analysis.sql`

4. **Rapport d'analyse** (√† g√©n√©rer) :
   - `docs/step_4_analysis_report.md` (5-10 pages)

5. **Dashboard Streamlit** (√† d√©velopper) :
   - `dashboards/streamlit_app.py`

---

## üõ†Ô∏è Technologies Utilis√©es

| Technologie | Usage | Version |
|-------------|-------|---------|
| **Python** | Langage principal | 3.11+ |
| **Snowflake** | Data warehouse | - |
| **Transformers (Hugging Face)** | Mod√®les NLP | 4.30+ |
| **PyTorch** | Backend ML | 2.0+ |
| **NLTK** | Sentiment analysis (VADER) | 3.8+ |
| **Pandas** | Manipulation de donn√©es | 2.0+ |
| **Matplotlib/Seaborn** | Visualisations statiques | - |
| **Plotly** | Visualisations interactives | 5.0+ |
| **Streamlit** | Dashboard (futur) | 1.30+ |

---

## üîÑ Workflow d'Ex√©cution

```mermaid
graph LR
    A[Snowflake] --> B[Extraction SQL]
    B --> C[EDA]
    C --> D[Zero-Shot NLP]
    D --> E[Relevance Score]
    E --> F[Visualisations]
    F --> G[Export Dashboard]
    G --> H[Streamlit App]
```

**Temps estim√©** : 30-60 minutes (selon volume de donn√©es et GPU)

---

## ‚ö†Ô∏è Limitations & Am√©liorations

### Limitations actuelles

1. **√âchantillon unique** : Analyse limit√©e √† 1 produit
2. **Mod√®le non fine-tun√©** : Pr√©cision ~75% (vs 90%+ possible)
3. **Pas de d√©tection de spam** : Reviews fake non filtr√©es
4. **Scalabilit√©** : Temps d'inf√©rence √©lev√© sur CPU

### Roadmap d'am√©lioration

**Court terme** :
- [ ] Validation sur dataset labellis√© (500-1000 reviews)
- [ ] Extension √† 10-20 produits de cat√©gories vari√©es
- [ ] Optimisation du seuil de relevance_score

**Moyen terme** :
- [ ] Fine-tuning du mod√®le BART
- [ ] D√©tection de spam avanc√©e
- [ ] Pipeline automatis√© (Airflow)

**Long terme** :
- [ ] Mod√®le custom multi-t√¢ches
- [ ] A/B Testing impact business
- [ ] API temps r√©el (FastAPI)

---

## üìö Ressources & R√©f√©rences

### Documentation officielle
- [Hugging Face - Zero-Shot Classification](https://huggingface.co/tasks/zero-shot-classification)
- [VADER Sentiment Analysis](https://github.com/cjhutto/vaderSentiment)
- [Snowflake Python Connector](https://docs.snowflake.com/en/user-guide/python-connector)
- [Streamlit Documentation](https://docs.streamlit.io)

### Papers
- [BART: Denoising Sequence-to-Sequence Pre-training](https://arxiv.org/abs/1910.13461)
- [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654)

### Mod√®les utilis√©s
- [facebook/bart-large-mnli](https://huggingface.co/facebook/bart-large-mnli)
- [MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7](https://huggingface.co/MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7)

---

## ü§ù Support & Contact

Pour toute question sur ce case study :

1. **Consulter le notebook** : Commentaires d√©taill√©s dans chaque cellule
2. **V√©rifier les SQL queries** : `/notebooks/sql_queries/`
3. **Examiner les visualisations** : `/data/outputs/visualizations/`
4. **Lire le rapport final** : `/docs/step_4_analysis_report.md` (apr√®s g√©n√©ration)

---

## ‚úÖ Checklist de Compl√©tion

- [ ] Connexion Snowflake fonctionnelle
- [ ] Extraction des donn√©es compl√®te
- [ ] EDA avec visualisations sauvegard√©es
- [ ] Mod√®le NLP impl√©ment√© et test√©
- [ ] Relevance score calcul√©
- [ ] Visualisations finales export√©es
- [ ] Donn√©es sauvegard√©es (Snowflake + local)
- [ ] Dashboard Streamlit d√©velopp√©
- [ ] Rapport final g√©n√©r√© (5-10 pages)

---

**Derni√®re mise √† jour** : 2025-11-03
**Version** : 1.0
**Status** : Structure cr√©√©e, pr√™t pour ex√©cution
